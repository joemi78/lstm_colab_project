{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"xcx_ZdQjalKf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757172722756,"user_tz":-480,"elapsed":1778,"user":{"displayName":"æŽå®—ç©Ž","userId":"06893125105939496608"}},"outputId":"d3251d9b-96ac-4594-ec51-43dcb1c3b7df"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content\n","/content/drive/MyDrive/LSTM_PROGRAM\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)\n","%cd /content\n","\n","# åˆ‡åˆ°ä½ çš„å°ˆæ¡ˆè³‡æ–™å¤¾\n","%cd /content/drive/MyDrive/LSTM_PROGRAM\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"1Cz_yrlDiZ7D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757172937005,"user_tz":-480,"elapsed":28512,"user":{"displayName":"æŽå®—ç©Ž","userId":"06893125105939496608"}},"outputId":"a4f84efa-e62b-442a-8a33-97bf20ea05f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Day   / crypto: 4 æª”\n","Day   / stock : 4 æª”\n","Day   / bonds : 6 æª”\n","Day   / others: 1 æª”\n","Hour  / crypto: 4 æª”\n","Hour  / stock : 4 æª”\n","Hour  / bonds : 6 æª”\n","Hour  / others: 1 æª”\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/crypto_day_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/stock_day_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/bonds_day_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/others_day_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/crypto_hour_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/stock_hour_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/bonds_hour_aligned.csv\n","âœ… è¼¸å‡ºå®Œæˆï¼š./filtered_output/row_group/others_hour_aligned.csv\n"]}],"source":["import os\n","import pandas as pd\n","import re\n","from functools import reduce\n","\n","# 2. ã€ç”¨æˆ¶è‡ªå®šç¾©å€é–“ã€‘\n","start_date = '2022/04/28'\n","end_date = '2025/07/01'\n","start = pd.to_datetime(start_date)\n","end = pd.to_datetime(end_date)\n","\n","# è·¯å¾‘å’Œæª”å\n","folder = '.'\n","csv_files_day = [\n","    './source_data/BTCUSDT_DAY.csv',\n","    './source_data/ETHUSDT_DAY.csv',\n","    './source_data/CME_MINI_DL_ES1!, 1D.csv',\n","    './source_data/CME_MINI_DL_NQ1!, 1D.csv',\n","    './source_data/CBOT_MINI_DL_YM1!, 1D.csv',\n","    './source_data/CBOE_DLY_VX1!, 1D.csv',\n","    './source_data/CBOT_DL_ZN1!, 1D.csv',\n","    './source_data/CBOT_DL_ZT1!, 1D.csv',\n","    './source_data/CBOT_DL_ZF1!, 1D.csv',\n","    './source_data/CBOT_DL_TN1!, 1D.csv',\n","    './source_data/CBOT_DL_ZB1!, 1D.csv',\n","    './source_data/CME_DL_SR31!, 1D.csv',\n","#    './source_data/TVC_US10Y, 1D.csv',\n","    './source_data/COMEX_DL_GC1!, 1D.csv',\n","#    './source_data/BITSTAMP_DAIUSD, 1D.csv',\n","    './source_data/BITSTAMP_USDCUSD, 1D.csv',\n","    './source_data/BITSTAMP_USDTUSD, 1D.csv'\n","#    './source_data/TAIFEX_DLY_TXF1!, 1D.csv'\n","]\n","\n","csv_files_hour = [\n","    './source_data/BTCUSDT_HOUR.csv',\n","    './source_data/ETHUSDT_HOUR.csv',\n","    './source_data/CME_MINI_DL_ES1!, 60.csv',\n","    './source_data/CME_MINI_DL_NQ1!, 60.csv',\n","    './source_data/CBOT_MINI_DL_YM1!, 60.csv',\n","    './source_data/CBOE_DLY_VX1!, 60.csv',\n","    './source_data/CBOT_DL_ZN1!, 60.csv',\n","    './source_data/CBOT_DL_ZT1!, 60.csv',\n","    './source_data/CBOT_DL_ZF1!, 60.csv',\n","    './source_data/CBOT_DL_ZB1!, 60.csv',\n","    './source_data/CBOT_DL_TN1!, 60.csv',\n","    './source_data/CME_DL_SR31!, 60.csv',\n","#    './source_data/TVC_US10Y, 60.csv',\n","    './source_data/COMEX_DL_GC1!, 60.csv',\n","#    './source_data/BITSTAMP_DAIUSD, 60.csv',\n","    './source_data/Bitstamp_USDCUSD_1h_cleaned.csv',\n","    './source_data/Bitstamp_USDTUSD_1h_cleaned.csv'\n","# #    './source_data/TAIFEX_DLY_TXF1!, 60.csv'\n","]\n","def find_date_col(df):\n","    for col in df.columns:\n","        if 'date' in col.lower():\n","            return col\n","    return df.columns[0]\n","\n","\n","def get_prefix(file):\n","    if 'BTC' in file: return 'BTCUSDT'\n","    if 'ETH' in file: return 'ETHUSDT'\n","#    if 'DAI' in file: return 'DAIUSD'\n","    if 'USDCUSD' in file: return 'USDCUSD'\n","    if 'USDTUSD' in file: return 'USDTUSD'\n","    if 'ES1' in file: return 'ES1'\n","    if 'NQ1' in file: return 'NQ1'\n","    if 'YM1' in file: return 'YM1'\n","    if 'VX1' in file: return 'VIX'\n","    if 'ZN1' in file: return 'ZN1'\n","    if 'ZT1' in file: return 'ZT1'\n","    if 'ZF1' in file: return 'ZF1'\n","    if 'ZB1' in file: return 'ZB1'\n","    if 'TN1' in file: return 'TN1'\n","    if 'SR3' in file: return 'SR3'\n","#    if 'US10Y' in file: return 'US10Y'\n","    if 'GC1' in file: return 'GC1'\n","#    if 'DAI' in file: return 'DAIUSD'\n","    if 'USDCUSD' in file: return 'USDCUSD'\n","    if 'USDTUSD' in file: return 'USDTUSD'\n","#    if 'TXF1' in file: return 'TXF1'\n","    # fallback\n","    return os.path.splitext(os.path.basename(file))[0]\n","\n","# ä½ ä¹‹å¾Œå†å‘¼å« get_prefix(file) æ‰ä¸æœƒå‡ºéŒ¯\n","def impute_and_flag(df, start, end, freq, asset_prefix):\n","    # \"\"\"\n","    # df: å–®ä¸€è³‡ç”¢çš„ DataFrameï¼ˆå·²ç¶“æŠŠæ—¥æœŸæ¬„æ”¹åç‚º 'DATE'ï¼Œå…¶ä»–æ¬„å·²åŠ ä¸Šè³‡ç”¢å‰ç¶´ï¼‰\n","    # start, end: datetime-likeï¼Œå¯ç”¨ä½ ä¸Šé¢å®šç¾©çš„ start/end\n","    # freq: 'D' æˆ– 'H'\n","    # asset_prefix: ä¾‹å¦‚ 'ES1'ã€'BTCUSDT'ã€'ZN1'â€¦ï¼ˆç”¨ä¾†å‘½å is_trading æ¬„ä½ï¼‰\n","    # \"\"\"\n","    # 1) æ•´ç†æ™‚é–“æ¬„ä½ä¸¦æŽ’åº\n","    df = df.copy()\n","    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')\n","    df = df.dropna(subset=['DATE']).sort_values('DATE')\n","    df = df.loc[(df['DATE'] >= start) & (df['DATE'] <= end)]\n","\n","    # 2) å»ºç«‹å®Œæ•´ç´¢å¼•ä¸¦ reindex\n","    full_index = pd.date_range(start=start, end=end, freq=freq)\n","    df = df.set_index('DATE')\n","    original_idx = df.index\n","\n","    df = df.reindex(full_index)\n","\n","    # 3) is_trading æ¬„ï¼šåŽŸå§‹æœ‰åˆ—=1ï¼›è£œå‡ºçš„=0\n","    flag_col = f\"{asset_prefix}_is_trading\"\n","    df[flag_col] = 0\n","    df.loc[original_idx.intersection(df.index), flag_col] = 1\n","\n","    # 4) é‡å°æ¬„ä½é¡žåž‹è£œå€¼\n","    #   - OHLC â†’ ffill\n","    #   - VOLUME / VOLUME_BASE â†’ 0.0\n","    #   - å…¶ä»– â†’ ffill\n","    for col in df.columns:\n","        if col == flag_col:\n","            continue\n","        # æ³¨æ„ï¼šä½ çš„æ¬„ä½å·²ç¶“å«è³‡ç”¢å‰ç¶´ï¼Œå› æ­¤ç”¨ endswith åˆ¤æ–·å¾Œç¶´\n","        if col.endswith(('_OPEN', '_HIGH', '_LOW', '_CLOSE')):\n","            df[col] = df[col].ffill()\n","            # å¦‚æžœæ•´åˆ—éƒ½é‚„æ˜¯ NaNï¼Œå°±å¡« 0\n","            df[col] = df[col].fillna(0.0)\n","        elif col.endswith(('_VOLUME', '_VOLUME_BASE')):\n","            df[col] = df[col].fillna(0.0)\n","        else:\n","            df[col] = df[col].ffill()\n","            df[col] = df[col].fillna(0.0)\n","    # 5) æŠŠç´¢å¼•é‚„åŽŸç‚º DATE æ¬„ä½ï¼ˆç¶­æŒä½ æ—¢æœ‰æ…£ä¾‹ï¼‰\n","    df = df.reset_index().rename(columns={'index': 'DATE'})\n","\n","    return df\n","\n","def read_and_clean(file):\n","    df = pd.read_csv(file)\n","    date_col = find_date_col(df)\n","    tried = False\n","    for fmt in ['%Y-%m-%d %H:%M:%S', '%Y/%m/%d %H:%M', '%Y-%m-%d %H:%M', '%Y/%m/%d %H:%M:%S']:\n","        try:\n","            df[date_col] = pd.to_datetime(df[date_col], format=fmt, errors='raise')\n","            tried = True\n","            break\n","        except Exception:\n","            continue\n","    if not tried:\n","        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n","    # å¼·åˆ¶ floor åˆ°å°æ™‚ï¼Œé¿å…äº¤é›†å¤±æ•—\n","    df[date_col] = df[date_col].dt.floor('h')\n","    df[date_col] = df[date_col].dt.tz_localize(None)\n","    df = df.rename(columns={date_col: 'DATE'})\n","    return df\n","\n","dfs_day = []\n","for file in csv_files_day:\n","    df1 = pd.read_csv(os.path.join(folder, file))\n","    date_col1 = find_date_col(df1)\n","    df1[date_col1] = pd.to_datetime(df1[date_col1], errors='coerce')\n","    df1 = df1.dropna(subset=[date_col1])\n","    prefix = get_prefix(file)\n","    # å°‡æ‰€æœ‰éžæ—¥æœŸæ¬„ä½åŠ å‰ç¶´\n","    rename = {col: f\"{prefix}_{col.upper()}\" for col in df1.columns if col != date_col1}\n","    df1 = df1.rename(columns=rename)\n","    df1 = df1.rename(columns={date_col1: 'DATE'})\n","\n","    # ðŸ”½ðŸ”½ðŸ”½ã€æ–°å¢žã€‘æ—¥é »è£œå€¼ + æ——æ¨™ï¼ˆfreq='D'ï¼‰\n","    df1 = impute_and_flag(df1, start, end, freq='D', asset_prefix=prefix)\n","\n","    dfs_day.append(df1)\n","\n","dfs_hour = []\n","for file in csv_files_hour:\n","    df2 = read_and_clean(file)\n","    date_col2 = find_date_col(df2)\n","    df2[date_col2] = pd.to_datetime(df2[date_col2], errors='coerce')\n","    df2 = df2.dropna(subset=[date_col2])\n","    prefix = get_prefix(file)\n","    # å°‡æ‰€æœ‰éžæ—¥æœŸæ¬„ä½åŠ å‰ç¶´\n","    rename = {col: f\"{prefix}_{col.upper()}\" for col in df2.columns if col != date_col2}\n","    df2 = df2.rename(columns=rename)\n","    df2 = df2.rename(columns={date_col2: 'DATE'})\n","\n","    # ðŸ”½ðŸ”½ðŸ”½ã€æ–°å¢žã€‘å°æ™‚è£œå€¼ + æ——æ¨™ï¼ˆfreq='H'ï¼‰\n","    df2 = impute_and_flag(df2, start, end, freq='h', asset_prefix=prefix)\n","\n","    dfs_hour.append(df2)\n","\n","# print(f\"dfs_hour List\")\n","# for i, df in enumerate(dfs_hour):\n","#     print(f\"---- dfs_hour[{i}] ----\")\n","#     # print(f\"Shape: {df.shape}\")\n","#     print(\"Columns:\", df.columns.tolist())\n","#     #print(df.head(), \"\\n\")\n","# print(f\"\\ndfs_day List\")\n","# for i, df in enumerate(dfs_day):\n","#     print(f\"---- dfs_day[{i}] ----\")\n","#     # print(f\"Shape: {df.shape}\")\n","#     print(\"Columns:\", df.columns.tolist())\n","#     #print(df.head(), \"\\n\")\n","\n","# 1. prefix â†’ group å¯¹ç…§è¡¨ï¼Œä¸€å®šè¦æŠŠ list_prefixes é‡Œæ‰€æœ‰çš„éƒ½åŠ è¿›æ¥\n","GROUP_MAP = {\n","    'crypto': ['BTCUSDT','ETHUSDT','USDCUSD','USDTUSD'],\n","    'stock':  ['ES1','NQ1','YM1','VIX'],\n","    'bonds':  ['US10Y','ZN1','ZF1','ZT1','ZB1','TN1','SR3'],\n","    'others':  ['GC1']\n","}\n","\n","def classify_dfs(dfs):\n","    groups = { g: [] for g in GROUP_MAP }\n","    for df in dfs:\n","        prefix = get_prefix(df.columns[1].split('_',1)[0])\n","        for grp, prefixes in GROUP_MAP.items():\n","            if prefix in prefixes:\n","                groups[grp].append(df)\n","                break\n","        else:\n","            raise AssertionError(f\"å‰ç¼€ {prefix} æ²¡åˆ†åˆ°ç»„ï¼Œè¯·è¡¥å……åˆ° GROUP_MAP\")\n","    return groups\n","\n","\n","\n","day_groups  = classify_dfs(dfs_day)\n","hour_groups = classify_dfs(dfs_hour)\n","\n","for name, lst in day_groups.items():\n","    print(f\"Day   / {name:6s}: {len(lst)} æª”\")\n","for name, lst in hour_groups.items():\n","    print(f\"Hour  / {name:6s}: {len(lst)} æª”\")\n","\n","\n","\n","# å‡è¨­å‰é¢å·²ç¶“æœ‰ day_groups, hour_groups å…©å€‹ dict:\n","# { 'crypto':[df1,df2,â€¦], 'stock':[â€¦], 'bonds':[â€¦] }\n","merged = {}\n","for freq, groups in (('day',   day_groups),\n","                     ('hour', hour_groups)):\n","    for name, lst in groups.items():\n","        # ç”¨ reduce+merge åšäº¤é›†\n","        key = f\"df_merged_{freq}_{name}\"\n","        merged[key] = reduce(\n","            lambda left, right: pd.merge(left, right, on='DATE', how='inner'),\n","            lst\n","        )\n","\n","# merged è£¡å°±æœƒæœ‰\n","# merged['df_merged_day_crypto']\n","# merged['df_merged_day_stock']\n","# merged['df_merged_day_bonds']\n","# merged['df_merged_hour_crypto']\n","# merged['df_merged_hour_stock']\n","# merged['df_merged_hour_bonds']\n","\n","\n","# ä½ æƒ³è¦çš„ prefix é †åºï¼ˆä¸åœ¨è£¡é¢çš„ prefix å‰‡è·³éŽï¼‰\n","preferred_order = [\n","    'BTCUSDT', 'ETHUSDT','USDCUSD', 'USDTUSD',\n","    'ES1', 'NQ1', 'YM1','VIX',\n","    'SR3', 'ZT1', 'ZF1', 'TN1', 'ZN1','ZB1',\n","    'US10Y', 'GC1'\n","]\n","\n","# ç¢ºä¿ output ç›®éŒ„å­˜åœ¨\n","out_dir = \"./filtered_output/row_group/\"\n","os.makedirs(out_dir, exist_ok=True)\n","\n","for name, df in merged.items():\n","    # name æœƒé•·å¾—åƒ \"df_merged_hour_crypto\"ã€\"df_merged_day_stock\"â€¦\n","    # æˆ‘å€‘æŠŠå®ƒæ‹†æˆ freq + groupï¼Œç„¶å¾Œæ‰“å…¥æª”å\n","    _, _, freq, group = name.split(\"_\")\n","    out_path = os.path.join(out_dir, f\"{group}_{freq}_aligned.csv\")\n","\n","    # æŠŠ DATE æ”¾æœ€å‰é¢\n","    cols = [\"DATE\"]\n","\n","    # ç…§ä½ çš„ preferred_orderã€ä»¥åŠ [CLOSE, VOLUME, OPEN, HIGH, LOW] çš„é †åºæŒ‘æ¬„ä½\n","    for suffix in [\"CLOSE\", \"VOLUME\", \"OPEN\", \"HIGH\", \"LOW\", \"is_trading\"]:\n","        for prefix in preferred_order:\n","            col = f\"{prefix}_{suffix}\"\n","            if col in df.columns:\n","                cols.append(col)\n","\n","    # é‡æŽ’æ¬„ä½\n","    df_out = df[cols]\n","\n","    # å¯« CSV\n","    df_out.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n","    print(f\"âœ… è¼¸å‡ºå®Œæˆï¼š{out_path}\")\n","\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMedSw7V2aYaGQuQjRxVOUT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}